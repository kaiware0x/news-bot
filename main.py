import os
import feedparser
import requests
from datetime import datetime
from dateutil import parser as date_parser

DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")
NEWS_COUNT = int(os.getenv("NEWS_COUNT", 5))
RSS_FEEDS = os.getenv("RSS_FEEDS", "https://rss.itmedia.co.jp/rss/2.0/news_bursts.xml").split(",")

def fetch_news():
    all_articles = []
    for feed_url in RSS_FEEDS:
        one_site_articles = []
        feed = feedparser.parse(feed_url.strip())
        # for entry in feed.entries:
        #     pub_date = None
        #     if hasattr(entry, "published"):
        #         try:
        #             pub_date = date_parser.parse(entry.published)
        #         except Exception:
        #             pub_date = None
        #     one_site_articles.append({
        #         "title": entry.title,
        #         "link": entry.link,
        #         "published": pub_date
        #     })
        all_articles += feed.entries[:NEWS_COUNT]
    # æ—¥ä»˜ãŒã‚ã‚‹ã‚‚ã®ã¯æ–°ã—ã„é †ã«ã€ãªã‘ã‚Œã°å¾Œå›ã—
    # all_articles.sort(key=lambda x: x["published"] or datetime.min, reverse=True)
    return all_articles

def send_to_discord(articles):
    embeds = []
    for a in articles:
        embed = {
            "title": a.title,          # è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            "url": a.link,             # ã‚¯ãƒªãƒƒã‚¯ã§é£›ã¹ã‚‹ãƒªãƒ³ã‚¯
            "description": (a.summary if hasattr(a, "summary") else "ï¼ˆè¦ç´„ãªã—ï¼‰"),
            "color": 0x1E90FF          # é’è‰²ï¼ˆ16é€²æ•°ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ï¼‰
        }
        embeds.append(embed)

    data = {
        "content": "ğŸ“° ä»Šæ—¥ã®ITãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã“ã¡ã‚‰ï¼",
        "embeds": embeds
    }

    response = requests.post(DISCORD_WEBHOOK_URL, json=data)
    if response.status_code == 204:
        print("âœ… Discordã«é€ä¿¡ã—ã¾ã—ãŸï¼ï¼ˆEmbedå½¢å¼ï¼‰")
    else:
        print(f"âš ï¸ Discordé€ä¿¡å¤±æ•—: {response.status_code}, {response.text}")

if __name__ == "__main__":
    news = fetch_news()
    send_to_discord(news)
